{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom  datetime import datetime, timedelta","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Prepare Datasets for Training"},{"metadata":{},"cell_type":"markdown","source":"## Define the correct data type for each column in the datasets"},{"metadata":{},"cell_type":"markdown","source":"### *calendar.csv*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correct data types for \"calendar.csv\"\ncalendarDTypes = {\"event_name_1\": \"category\", \n                  \"event_name_2\": \"category\", \n                  \"event_type_1\": \"category\", \n                  \"event_type_2\": \"category\", \n                  \"weekday\": \"category\", \n                  'wm_yr_wk': 'int16', \n                  \"wday\": \"int16\",\n                  \"month\": \"int16\", \n                  \"year\": \"int16\", \n                  \"snap_CA\": \"float32\", \n                  'snap_TX': 'float32', \n                  'snap_WI': 'float32' }\n\n# Read csv file\ncalendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\", \n                       dtype = calendarDTypes)\n\ncalendar[\"date\"] = pd.to_datetime(calendar[\"date\"])\n\n# Transform categorical features into integers\nfor col, colDType in calendarDTypes.items():\n    if colDType == \"category\":\n        calendar[col] = calendar[col].cat.codes.astype(\"int16\")\n        calendar[col] -= calendar[col].min()\n\ncalendar.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"        date  wm_yr_wk  weekday  wday  month  year    d  event_name_1  \\\n0 2011-01-29     11101        2     1      1  2011  d_1             0   \n1 2011-01-30     11101        3     2      1  2011  d_2             0   \n2 2011-01-31     11101        1     3      1  2011  d_3             0   \n3 2011-02-01     11101        5     4      2  2011  d_4             0   \n4 2011-02-02     11101        6     5      2  2011  d_5             0   \n\n   event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  \n0             0             0             0      0.0      0.0      0.0  \n1             0             0             0      0.0      0.0      0.0  \n2             0             0             0      0.0      0.0      0.0  \n3             0             0             0      1.0      1.0      0.0  \n4             0             0             0      1.0      0.0      1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>weekday</th>\n      <th>wday</th>\n      <th>month</th>\n      <th>year</th>\n      <th>d</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-29</td>\n      <td>11101</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-30</td>\n      <td>11101</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-31</td>\n      <td>11101</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2011</td>\n      <td>d_3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-02-01</td>\n      <td>11101</td>\n      <td>5</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2011</td>\n      <td>d_4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-02-02</td>\n      <td>11101</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2011</td>\n      <td>d_5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### *sell_prices.csv*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correct data types for \"sell_prices.csv\"\npriceDTypes = {\"store_id\": \"category\", \n               \"item_id\": \"category\", \n               \"wm_yr_wk\": \"int16\",\n               \"sell_price\":\"float32\"}\n\n# Read csv file\nprices = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\", \n                     dtype = priceDTypes)\n\n# Transform categorical features into integers\nfor col, colDType in priceDTypes.items():\n    if colDType == \"category\":\n        prices[col] = prices[col].cat.codes.astype(\"int16\")\n        prices[col] -= prices[col].min()\n        \nprices.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   store_id  item_id  wm_yr_wk  sell_price\n0         0        0     11325        9.58\n1         0        0     11326        9.58\n2         0        0     11327        8.26\n3         0        0     11328        8.26\n4         0        0     11329        8.26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>store_id</th>\n      <th>item_id</th>\n      <th>wm_yr_wk</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11325</td>\n      <td>9.58</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11326</td>\n      <td>9.58</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11327</td>\n      <td>8.26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11328</td>\n      <td>8.26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>11329</td>\n      <td>8.26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### *sales_train_validation.csv*"},{"metadata":{"trusted":true},"cell_type":"code","source":"firstDay = 250\nlastDay = 1913\n\n# Use x sales days (columns) for training\nnumCols = [f\"d_{day}\" for day in range(firstDay, lastDay+1)]\n\n# Define all categorical columns\ncatCols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n\n# Define the correct data types for \"sales_train_validation.csv\"\ndtype = {numCol: \"float32\" for numCol in numCols} \ndtype.update({catCol: \"category\" for catCol in catCols if catCol != \"id\"})\n\n# Read csv file\nds = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", \n                 usecols = catCols + numCols, dtype = dtype)\n\n# Transform categorical features into integers\nfor col in catCols:\n    if col != \"id\":\n        ds[col] = ds[col].cat.codes.astype(\"int16\")\n        ds[col] -= ds[col].min()\n        \nds = pd.melt(ds,\n             id_vars = catCols,\n             value_vars = [col for col in ds.columns if col.startswith(\"d_\")],\n             var_name = \"d\",\n             value_name = \"sales\")\n\n# Merge \"ds\" with \"calendar\" and \"prices\" dataframe\nds = ds.merge(calendar, on = \"d\", copy = False)\nds = ds.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n\nds.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                              id  item_id  dept_id  store_id  cat_id  \\\n0  HOBBIES_1_002_CA_1_validation        1        0         0       0   \n1  HOBBIES_1_002_CA_1_validation        1        0         0       0   \n2  HOBBIES_1_002_CA_1_validation        1        0         0       0   \n3  HOBBIES_1_004_CA_1_validation        3        0         0       0   \n4  HOBBIES_1_004_CA_1_validation        3        0         0       0   \n\n   state_id      d  sales       date  wm_yr_wk  ...  month  year  \\\n0         0  d_250    0.0 2011-10-05     11136  ...     10  2011   \n1         0  d_251    0.0 2011-10-06     11136  ...     10  2011   \n2         0  d_252    0.0 2011-10-07     11136  ...     10  2011   \n3         0  d_250    0.0 2011-10-05     11136  ...     10  2011   \n4         0  d_251    4.0 2011-10-06     11136  ...     10  2011   \n\n   event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  \\\n0             0             0             0             0      1.0      1.0   \n1             0             0             0             0      1.0      1.0   \n2             0             0             0             0      1.0      1.0   \n3             0             0             0             0      1.0      1.0   \n4             0             0             0             0      1.0      1.0   \n\n   snap_WI  sell_price  \n0      1.0        3.97  \n1      1.0        3.97  \n2      0.0        3.97  \n3      1.0        4.34  \n4      1.0        4.34  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>store_id</th>\n      <th>cat_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>month</th>\n      <th>year</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_250</td>\n      <td>0.0</td>\n      <td>2011-10-05</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>10</td>\n      <td>2011</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_251</td>\n      <td>0.0</td>\n      <td>2011-10-06</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>10</td>\n      <td>2011</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_252</td>\n      <td>0.0</td>\n      <td>2011-10-07</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>10</td>\n      <td>2011</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.97</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_validation</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_250</td>\n      <td>0.0</td>\n      <td>2011-10-05</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>10</td>\n      <td>2011</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_004_CA_1_validation</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_251</td>\n      <td>4.0</td>\n      <td>2011-10-06</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>10</td>\n      <td>2011</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.34</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Create features"},{"metadata":{},"cell_type":"markdown","source":"### Sales features"},{"metadata":{"trusted":true},"cell_type":"code","source":"dayLags = [7, 28]\nlagSalesCols = [f\"lag_{dayLag}\" for dayLag in dayLags]\nfor dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n    ds[lagSalesCol] = ds[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(dayLag)\n    \nwindows = [7, 28]\nfor window in windows:\n    for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n        ds[f\"rmean_{dayLag}_{window}\"] = ds[[\"id\", lagSalesCol]].groupby(\"id\")[lagSalesCol].transform(lambda x: x.rolling(window).mean())","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Date features"},{"metadata":{"trusted":true},"cell_type":"code","source":"dateFeatures = {\"wday\": \"weekday\",\n                \"week\": \"weekofyear\",\n                \"month\": \"month\",\n                \"quarter\": \"quarter\",\n                \"year\": \"year\",\n                \"mday\": \"day\"}\n\nfor featName, featFunc in dateFeatures.items():\n    if featName in ds.columns:\n        ds[featName] = ds[featName].astype(\"int16\")\n    else:\n        ds[featName] = getattr(ds[\"date\"].dt, featFunc).astype(\"int16\")","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                              id  item_id  dept_id  store_id  cat_id  \\\n0  HOBBIES_1_002_CA_1_validation        1        0         0       0   \n1  HOBBIES_1_002_CA_1_validation        1        0         0       0   \n2  HOBBIES_1_002_CA_1_validation        1        0         0       0   \n3  HOBBIES_1_004_CA_1_validation        3        0         0       0   \n4  HOBBIES_1_004_CA_1_validation        3        0         0       0   \n\n   state_id      d  sales       date  wm_yr_wk  ...  sell_price  lag_7  \\\n0         0  d_250    0.0 2011-10-05     11136  ...        3.97    NaN   \n1         0  d_251    0.0 2011-10-06     11136  ...        3.97    NaN   \n2         0  d_252    0.0 2011-10-07     11136  ...        3.97    NaN   \n3         0  d_250    0.0 2011-10-05     11136  ...        4.34    NaN   \n4         0  d_251    4.0 2011-10-06     11136  ...        4.34    NaN   \n\n   lag_28  rmean_7_7  rmean_28_7  rmean_7_28  rmean_28_28  week  quarter  mday  \n0     NaN        NaN         NaN         NaN          NaN    40        4     5  \n1     NaN        NaN         NaN         NaN          NaN    40        4     6  \n2     NaN        NaN         NaN         NaN          NaN    40        4     7  \n3     NaN        NaN         NaN         NaN          NaN    40        4     5  \n4     NaN        NaN         NaN         NaN          NaN    40        4     6  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>store_id</th>\n      <th>cat_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>...</th>\n      <th>sell_price</th>\n      <th>lag_7</th>\n      <th>lag_28</th>\n      <th>rmean_7_7</th>\n      <th>rmean_28_7</th>\n      <th>rmean_7_28</th>\n      <th>rmean_28_28</th>\n      <th>week</th>\n      <th>quarter</th>\n      <th>mday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_250</td>\n      <td>0.0</td>\n      <td>2011-10-05</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>3.97</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_251</td>\n      <td>0.0</td>\n      <td>2011-10-06</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>3.97</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_252</td>\n      <td>0.0</td>\n      <td>2011-10-07</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>3.97</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_004_CA_1_validation</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_250</td>\n      <td>0.0</td>\n      <td>2011-10-05</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>4.34</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_004_CA_1_validation</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_251</td>\n      <td>4.0</td>\n      <td>2011-10-06</td>\n      <td>11136</td>\n      <td>...</td>\n      <td>4.34</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.info()","execution_count":9,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 42372682 entries, 0 to 42372681\nData columns (total 31 columns):\nid              object\nitem_id         int16\ndept_id         int16\nstore_id        int16\ncat_id          int16\nstate_id        int16\nd               object\nsales           float32\ndate            datetime64[ns]\nwm_yr_wk        int16\nweekday         int16\nwday            int16\nmonth           int16\nyear            int16\nevent_name_1    int16\nevent_type_1    int16\nevent_name_2    int16\nevent_type_2    int16\nsnap_CA         float32\nsnap_TX         float32\nsnap_WI         float32\nsell_price      float32\nlag_7           float32\nlag_28          float32\nrmean_7_7       float32\nrmean_28_7      float32\nrmean_7_28      float32\nrmean_28_28     float32\nweek            int16\nquarter         int16\nmday            int16\ndtypes: datetime64[ns](1), float32(11), int16(17), object(2)\nmemory usage: 4.3+ GB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Remove unnecessary rows and columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove all rows with NaN value\nds.dropna(inplace = True)\n\n# Define columns that need to be removed\nunusedCols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\ntrainCols = ds.columns[~ds.columns.isin(unusedCols)]\nX_train = ds[trainCols]\ny_train = ds[\"sales\"]","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split dataset into train and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(777)\n\n# Define categorical features\ncatFeats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + \\\n           [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n\nvalidInds = np.random.choice(X_train.index.values, 2_000_000, replace = False)\ntrainInds = np.setdiff1d(X_train.index.values, validInds)\n\ntrainData = lgb.Dataset(X_train.loc[trainInds], label = y_train.loc[trainInds], \n                        categorical_feature = catFeats, free_raw_data = False)\nvalidData = lgb.Dataset(X_train.loc[validInds], label = y_train.loc[validInds],\n                        categorical_feature = catFeats, free_raw_data = False)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del ds, X_train, y_train, validInds, trainInds ; gc.collect()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n          \"objective\" : \"poisson\",\n          \"metric\" :\"rmse\",\n          \"force_row_wise\" : True,\n          \"learning_rate\" : 0.075,\n          \"sub_row\" : 0.75,\n          \"bagging_freq\" : 1,\n          \"lambda_l2\" : 0.1,\n          \"metric\": [\"rmse\"],\n          'verbosity': 1,\n          'num_iterations' : 1200,\n          'num_leaves': 128,\n          \"min_data_in_leaf\": 100,\n         }","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train LightGBM model\nm_lgb = lgb.train(params, trainData, valid_sets = [validData], verbose_eval = 20) ","execution_count":14,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n  warnings.warn('Using categorical_feature in Dataset.')\n","name":"stderr"},{"output_type":"stream","text":"[20]\tvalid_0's rmse: 3.31172\n[40]\tvalid_0's rmse: 2.71122\n[60]\tvalid_0's rmse: 2.54446\n[80]\tvalid_0's rmse: 2.49506\n[100]\tvalid_0's rmse: 2.48035\n[120]\tvalid_0's rmse: 2.46893\n[140]\tvalid_0's rmse: 2.46009\n[160]\tvalid_0's rmse: 2.45151\n[180]\tvalid_0's rmse: 2.44121\n[200]\tvalid_0's rmse: 2.43275\n[220]\tvalid_0's rmse: 2.42633\n[240]\tvalid_0's rmse: 2.42221\n[260]\tvalid_0's rmse: 2.41521\n[280]\tvalid_0's rmse: 2.4111\n[300]\tvalid_0's rmse: 2.4058\n[320]\tvalid_0's rmse: 2.40227\n[340]\tvalid_0's rmse: 2.39758\n[360]\tvalid_0's rmse: 2.39348\n[380]\tvalid_0's rmse: 2.39023\n[400]\tvalid_0's rmse: 2.38645\n[420]\tvalid_0's rmse: 2.38293\n[440]\tvalid_0's rmse: 2.38022\n[460]\tvalid_0's rmse: 2.37631\n[480]\tvalid_0's rmse: 2.37461\n[500]\tvalid_0's rmse: 2.37166\n[520]\tvalid_0's rmse: 2.36952\n[540]\tvalid_0's rmse: 2.36694\n[560]\tvalid_0's rmse: 2.36379\n[580]\tvalid_0's rmse: 2.36169\n[600]\tvalid_0's rmse: 2.36007\n[620]\tvalid_0's rmse: 2.35766\n[640]\tvalid_0's rmse: 2.35619\n[660]\tvalid_0's rmse: 2.35461\n[680]\tvalid_0's rmse: 2.35276\n[700]\tvalid_0's rmse: 2.35055\n[720]\tvalid_0's rmse: 2.34893\n[740]\tvalid_0's rmse: 2.34676\n[760]\tvalid_0's rmse: 2.34517\n[780]\tvalid_0's rmse: 2.3436\n[800]\tvalid_0's rmse: 2.34253\n[820]\tvalid_0's rmse: 2.34073\n[840]\tvalid_0's rmse: 2.3392\n[860]\tvalid_0's rmse: 2.33765\n[880]\tvalid_0's rmse: 2.33655\n[900]\tvalid_0's rmse: 2.33526\n[920]\tvalid_0's rmse: 2.33423\n[940]\tvalid_0's rmse: 2.33349\n[960]\tvalid_0's rmse: 2.33205\n[980]\tvalid_0's rmse: 2.32983\n[1000]\tvalid_0's rmse: 2.32844\n[1020]\tvalid_0's rmse: 2.32704\n[1040]\tvalid_0's rmse: 2.32634\n[1060]\tvalid_0's rmse: 2.3257\n[1080]\tvalid_0's rmse: 2.32496\n[1100]\tvalid_0's rmse: 2.32411\n[1120]\tvalid_0's rmse: 2.32372\n[1140]\tvalid_0's rmse: 2.32279\n[1160]\tvalid_0's rmse: 2.32229\n[1180]\tvalid_0's rmse: 2.32139\n[1200]\tvalid_0's rmse: 2.32033\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the model\nm_lgb.save_model(\"model.lgb\")","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"<lightgbm.basic.Booster at 0x7ff041be3a20>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Last day used for training\ntrLast = 1913\n# Maximum lag day\nmaxLags = 57\n\n# Create dataset for predictions\ndef create_ds():\n    \n    startDay = trLast - maxLags\n    \n    numCols = [f\"d_{day}\" for day in range(startDay, trLast + 1)]\n    catCols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n    \n    dtype = {numCol:\"float32\" for numCol in numCols} \n    dtype.update({catCol: \"category\" for catCol in catCols if catCol != \"id\"})\n    \n    ds = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", \n                     usecols = catCols + numCols, dtype = dtype)\n    \n    for col in catCols:\n        if col != \"id\":\n            ds[col] = ds[col].cat.codes.astype(\"int16\")\n            ds[col] -= ds[col].min()\n    \n    for day in range(trLast + 1, trLast+ 28 +1):\n        ds[f\"d_{day}\"] = np.nan\n    \n    ds = pd.melt(ds,\n                 id_vars = catCols,\n                 value_vars = [col for col in ds.columns if col.startswith(\"d_\")],\n                 var_name = \"d\",\n                 value_name = \"sales\")\n    \n    ds = ds.merge(calendar, on = \"d\", copy = False)\n    ds = ds.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n    \n    return ds\n\ndef create_features(ds):          \n    dayLags = [7, 28]\n    lagSalesCols = [f\"lag_{dayLag}\" for dayLag in dayLags]\n    for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n        ds[lagSalesCol] = ds[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(dayLag)\n\n    windows = [7, 28]\n    for window in windows:\n        for dayLag, lagSalesCol in zip(dayLags, lagSalesCols):\n            ds[f\"rmean_{dayLag}_{window}\"] = ds[[\"id\", lagSalesCol]].groupby(\"id\")[lagSalesCol].transform(lambda x: x.rolling(window).mean())\n          \n    dateFeatures = {\"wday\": \"weekday\",\n                    \"week\": \"weekofyear\",\n                    \"month\": \"month\",\n                    \"quarter\": \"quarter\",\n                    \"year\": \"year\",\n                    \"mday\": \"day\"}\n\n    for featName, featFunc in dateFeatures.items():\n        if featName in ds.columns:\n            ds[featName] = ds[featName].astype(\"int16\")\n        else:\n            ds[featName] = getattr(ds[\"date\"].dt, featFunc).astype(\"int16\")","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fday = datetime(2016,4, 25) \nalphas = [1.028, 1.023, 1.018]\nweights = [1/len(alphas)] * len(alphas)\nsub = 0.\n\nfor icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n\n    te = create_ds()\n    cols = [f\"F{i}\" for i in range(1,29)]\n\n    for tdelta in range(0, 28):\n        day = fday + timedelta(days=tdelta)\n        print(tdelta, day)\n        tst = te[(te['date'] >= day - timedelta(days=maxLags)) & (te['date'] <= day)].copy()\n        create_features(tst)\n        tst = tst.loc[tst['date'] == day , trainCols]\n        te.loc[te['date'] == day, \"sales\"] = alpha * m_lgb.predict(tst) # magic multiplier by kyakovlev\n\n    te_sub = te.loc[te['date'] >= fday, [\"id\", \"sales\"]].copy()\n    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n    te_sub = te_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n    te_sub.fillna(0., inplace = True)\n    te_sub.sort_values(\"id\", inplace = True)\n    te_sub.reset_index(drop=True, inplace = True)\n    te_sub.to_csv(f\"submission_{icount}.csv\",index=False)\n    if icount == 0 :\n        sub = te_sub\n        sub[cols] *= weight\n    else:\n        sub[cols] += te_sub[cols]*weight\n    print(icount, alpha, weight)\n\n\nsub2 = sub.copy()\nsub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\nsub = pd.concat([sub, sub2], axis=0, sort=False)\nsub.to_csv(\"submission_lightgbm.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}